{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "RXE-EC9tVsXW"
   },
   "source": [
    "# Homework 2, *part 2* (60 points)\n",
    "\n",
    "In this assignment you will build a heavy convolutional neural net (CNN) to solve Tiny ImageNet image classification. Try to achieve as high accuracy as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HjJXGmPVsXX"
   },
   "source": [
    "## Deliverables\n",
    "\n",
    "* This file,\n",
    "* a \"checkpoint file\" from `torch.save(model.state_dict(), ...)` that contains model's weights (which a TA should be able to load to verify your accuracy).\n",
    "\n",
    "## Grading\n",
    "\n",
    "* 9 points for reproducible training code and a filled report below.\n",
    "* 12 points for building a network that gets above 20% accuracy.\n",
    "* 6.5 points for beating each of these milestones on the validation set:\n",
    "  * 25.0%\n",
    "  * 30.0%\n",
    "  * 32.5%\n",
    "  * 35.0%\n",
    "  * 37.5%\n",
    "  * 40.0%\n",
    "    \n",
    "## Restrictions\n",
    "\n",
    "* Don't use pretrained networks.\n",
    "\n",
    "## Tips\n",
    "\n",
    "* One change at a time: never test several new things at once.\n",
    "* Google a lot.\n",
    "* Use GPU.\n",
    "* Use regularization: L2, batch normalization, dropout, data augmentation.\n",
    "* Use Tensorboard ([non-Colab](https://github.com/lanpa/tensorboardX) or [Colab](https://medium.com/@tommytao_54597/use-tensorboard-in-google-colab-16b4bb9812a6)) or a similar interactive tool for viewing progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Me8ztJhHVsXZ"
   },
   "source": [
    "# I add here tips from  [SDA](https://github.com/yandexdataschool/Practical_DL/blob/spring2019/homework02/homework_part2.ipynb) for myself\n",
    "\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfLhbUmcVsXb"
   },
   "source": [
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "   * You should certainly use adaptive optimizers\n",
    "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "evWHO9OzVsXc"
   },
   "source": [
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbyGqNN_VsXe"
   },
   "source": [
    "  \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.ImageFolder(root=path_to_tiny_imagenet, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcRzPbJVVsXg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4hLgqX2VsXj"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# if you're running in colab,\n",
    "# 1. go to Runtime -> Change Runtimy Type -> GPU\n",
    "# 2. uncomment this:\n",
    "# !wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/spring2019/week03_convnets/tiny_img.py -O tiny_img.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7VvVoJcjVsXl",
    "outputId": "8b1181f8-fe57-4f62-de5c-92628db9ed6d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tiny-imagenet-200 already exists, not downloading\n"
     ]
    }
   ],
   "source": [
    "import tiny_imagenet\n",
    "tiny_imagenet.download(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eg55Snlaxzhi"
   },
   "source": [
    "#### Let's make Data Augmentation (like it was mentioned on seminar and https://github.com/yandexdataschool/Practical_DL/blob/spring2019/homework02/homework_part2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XcPnOPfqpmb"
   },
   "outputs": [],
   "source": [
    "imagenet_mean = np.array((0.4914, 0.4822, 0.4465))\n",
    "imagenet_std = np.array((0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(64),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2smknbhAVsXp"
   },
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform_train)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HszVKi9AVsXs"
   },
   "source": [
    "Training and validation images are now in `tiny-imagenet-200/train` and `tiny-imagenet-200/val`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVJcKPI7xzho"
   },
   "source": [
    "#### Fix random_seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qeq9pfnmfeHx",
    "outputId": "6921b39f-c62f-4530-b60b-747e569dcc78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3703daca50>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(127)\n",
    "torch.manual_seed(127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Xo-Ii90VsXs"
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFeAYEkwVsXv"
   },
   "outputs": [],
   "source": [
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujRpan3bVsXy"
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TgNfnx0VsX0"
   },
   "source": [
    "#### Let's start with a dense network for our baseline(like seminar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tE3Kd59iVsX1"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "# reshape from \"images\" to flat vectors\n",
    "model.add_module('flatten', Flatten())\n",
    "\n",
    "# dense \"head\"\n",
    "model.add_module('dense1', nn.Linear(3 * 64 * 64, 1064))\n",
    "model.add_module('dense2', nn.Linear(1064, 512))\n",
    "model.add_module('dropout0', nn.Dropout(0.05)) \n",
    "model.add_module('dense3', nn.Linear(512, 256))\n",
    "model.add_module('dropout1', nn.Dropout(0.05))\n",
    "model.add_module('dense4', nn.Linear(256, 64))\n",
    "model.add_module('dropout2', nn.Dropout(0.05))\n",
    "model.add_module('dense1_relu', nn.ReLU())\n",
    "model.add_module('dense2_logits', nn.Linear(64, 200)) # logits for 200 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4UZcE0qVsX3"
   },
   "outputs": [],
   "source": [
    "#  negative log-likelihood aka crossentropy.\n",
    "def compute_loss(X_batch, y_batch):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()\n",
    "    y_batch = Variable(torch.LongTensor(y_batch)).cuda()\n",
    "    logits = model.cuda()(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2567
    },
    "colab_type": "code",
    "id": "m_i7iXSvVsX5",
    "outputId": "8b677e98-ce1b-41de-f3e3-a7ae90c1463f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50 took 57.029s\n",
      "  training loss (in-iteration): \t4.682038\n",
      "  validation accuracy: \t\t\t6.42 %\n",
      "Epoch 2 of 50 took 56.634s\n",
      "  training loss (in-iteration): \t4.656852\n",
      "  validation accuracy: \t\t\t6.67 %\n",
      "Epoch 3 of 50 took 57.060s\n",
      "  training loss (in-iteration): \t4.635980\n",
      "  validation accuracy: \t\t\t6.66 %\n",
      "Epoch 4 of 50 took 56.976s\n",
      "  training loss (in-iteration): \t4.611738\n",
      "  validation accuracy: \t\t\t7.24 %\n",
      "Epoch 5 of 50 took 57.391s\n",
      "  training loss (in-iteration): \t4.588957\n",
      "  validation accuracy: \t\t\t6.99 %\n",
      "Epoch 6 of 50 took 57.603s\n",
      "  training loss (in-iteration): \t4.570151\n",
      "  validation accuracy: \t\t\t7.63 %\n",
      "Epoch 7 of 50 took 57.373s\n",
      "  training loss (in-iteration): \t4.551406\n",
      "  validation accuracy: \t\t\t6.95 %\n",
      "Epoch 8 of 50 took 57.512s\n",
      "  training loss (in-iteration): \t4.534232\n",
      "  validation accuracy: \t\t\t7.67 %\n",
      "Epoch 9 of 50 took 57.602s\n",
      "  training loss (in-iteration): \t4.517220\n",
      "  validation accuracy: \t\t\t8.01 %\n",
      "Epoch 10 of 50 took 57.624s\n",
      "  training loss (in-iteration): \t4.502809\n",
      "  validation accuracy: \t\t\t8.13 %\n",
      "Epoch 11 of 50 took 58.025s\n",
      "  training loss (in-iteration): \t4.485519\n",
      "  validation accuracy: \t\t\t8.17 %\n",
      "Epoch 12 of 50 took 57.528s\n",
      "  training loss (in-iteration): \t4.475089\n",
      "  validation accuracy: \t\t\t8.18 %\n",
      "Epoch 13 of 50 took 57.404s\n",
      "  training loss (in-iteration): \t4.460288\n",
      "  validation accuracy: \t\t\t8.43 %\n",
      "Epoch 14 of 50 took 57.796s\n",
      "  training loss (in-iteration): \t4.450960\n",
      "  validation accuracy: \t\t\t8.30 %\n",
      "Epoch 15 of 50 took 57.781s\n",
      "  training loss (in-iteration): \t4.435322\n",
      "  validation accuracy: \t\t\t8.46 %\n",
      "Epoch 16 of 50 took 57.767s\n",
      "  training loss (in-iteration): \t4.423930\n",
      "  validation accuracy: \t\t\t8.80 %\n",
      "Epoch 17 of 50 took 58.062s\n",
      "  training loss (in-iteration): \t4.407651\n",
      "  validation accuracy: \t\t\t8.68 %\n",
      "Epoch 18 of 50 took 57.022s\n",
      "  training loss (in-iteration): \t4.400631\n",
      "  validation accuracy: \t\t\t8.52 %\n",
      "Epoch 19 of 50 took 57.248s\n",
      "  training loss (in-iteration): \t4.388137\n",
      "  validation accuracy: \t\t\t8.55 %\n",
      "Epoch 20 of 50 took 56.919s\n",
      "  training loss (in-iteration): \t4.379746\n",
      "  validation accuracy: \t\t\t9.06 %\n",
      "Epoch 21 of 50 took 56.909s\n",
      "  training loss (in-iteration): \t4.366891\n",
      "  validation accuracy: \t\t\t8.89 %\n",
      "Epoch 22 of 50 took 57.331s\n",
      "  training loss (in-iteration): \t4.357205\n",
      "  validation accuracy: \t\t\t8.68 %\n",
      "Epoch 23 of 50 took 56.710s\n",
      "  training loss (in-iteration): \t4.345946\n",
      "  validation accuracy: \t\t\t8.59 %\n",
      "Epoch 24 of 50 took 57.635s\n",
      "  training loss (in-iteration): \t4.334952\n",
      "  validation accuracy: \t\t\t9.22 %\n",
      "Epoch 25 of 50 took 57.389s\n",
      "  training loss (in-iteration): \t4.325964\n",
      "  validation accuracy: \t\t\t8.87 %\n",
      "Epoch 26 of 50 took 57.391s\n",
      "  training loss (in-iteration): \t4.314552\n",
      "  validation accuracy: \t\t\t9.25 %\n",
      "Epoch 27 of 50 took 57.270s\n",
      "  training loss (in-iteration): \t4.305554\n",
      "  validation accuracy: \t\t\t9.23 %\n",
      "Epoch 28 of 50 took 57.610s\n",
      "  training loss (in-iteration): \t4.299186\n",
      "  validation accuracy: \t\t\t9.11 %\n",
      "Epoch 29 of 50 took 57.689s\n",
      "  training loss (in-iteration): \t4.288525\n",
      "  validation accuracy: \t\t\t9.15 %\n",
      "Epoch 30 of 50 took 57.711s\n",
      "  training loss (in-iteration): \t4.279945\n",
      "  validation accuracy: \t\t\t9.07 %\n",
      "Epoch 31 of 50 took 57.689s\n",
      "  training loss (in-iteration): \t4.270462\n",
      "  validation accuracy: \t\t\t8.90 %\n",
      "Epoch 32 of 50 took 57.636s\n",
      "  training loss (in-iteration): \t4.264622\n",
      "  validation accuracy: \t\t\t9.08 %\n",
      "Epoch 33 of 50 took 58.184s\n",
      "  training loss (in-iteration): \t4.250820\n",
      "  validation accuracy: \t\t\t8.44 %\n",
      "Epoch 34 of 50 took 57.904s\n",
      "  training loss (in-iteration): \t4.244340\n",
      "  validation accuracy: \t\t\t8.91 %\n",
      "Epoch 35 of 50 took 58.210s\n",
      "  training loss (in-iteration): \t4.235403\n",
      "  validation accuracy: \t\t\t8.71 %\n",
      "Epoch 36 of 50 took 57.799s\n",
      "  training loss (in-iteration): \t4.228998\n",
      "  validation accuracy: \t\t\t9.22 %\n",
      "Epoch 37 of 50 took 57.789s\n",
      "  training loss (in-iteration): \t4.219500\n",
      "  validation accuracy: \t\t\t9.21 %\n",
      "Epoch 38 of 50 took 58.325s\n",
      "  training loss (in-iteration): \t4.210546\n",
      "  validation accuracy: \t\t\t9.31 %\n",
      "Epoch 39 of 50 took 57.965s\n",
      "  training loss (in-iteration): \t4.200835\n",
      "  validation accuracy: \t\t\t9.22 %\n",
      "Epoch 40 of 50 took 58.008s\n",
      "  training loss (in-iteration): \t4.195755\n",
      "  validation accuracy: \t\t\t9.12 %\n",
      "Epoch 41 of 50 took 57.729s\n",
      "  training loss (in-iteration): \t4.188186\n",
      "  validation accuracy: \t\t\t9.19 %\n",
      "Epoch 42 of 50 took 57.830s\n",
      "  training loss (in-iteration): \t4.178683\n",
      "  validation accuracy: \t\t\t8.89 %\n",
      "Epoch 43 of 50 took 57.900s\n",
      "  training loss (in-iteration): \t4.172809\n",
      "  validation accuracy: \t\t\t9.39 %\n",
      "Epoch 44 of 50 took 58.443s\n",
      "  training loss (in-iteration): \t4.165315\n",
      "  validation accuracy: \t\t\t9.42 %\n",
      "Epoch 45 of 50 took 57.695s\n",
      "  training loss (in-iteration): \t4.155782\n",
      "  validation accuracy: \t\t\t8.77 %\n",
      "Epoch 46 of 50 took 57.696s\n",
      "  training loss (in-iteration): \t4.148237\n",
      "  validation accuracy: \t\t\t9.11 %\n",
      "Epoch 47 of 50 took 56.756s\n",
      "  training loss (in-iteration): \t4.141520\n",
      "  validation accuracy: \t\t\t9.01 %\n",
      "Epoch 48 of 50 took 56.644s\n",
      "  training loss (in-iteration): \t4.134240\n",
      "  validation accuracy: \t\t\t9.02 %\n",
      "Epoch 49 of 50 took 57.289s\n",
      "  training loss (in-iteration): \t4.125606\n",
      "  validation accuracy: \t\t\t8.79 %\n",
      "Epoch 50 of 50 took 55.714s\n",
      "  training loss (in-iteration): \t4.117220\n",
      "  validation accuracy: \t\t\t8.63 %\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "import numpy as np\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "num_epochs = 50 # total amount of full passes over training data\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for (X_batch, y_batch) in train_batch_gen:\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "    \n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_batch_gen:\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZUIfyDKrH-E"
   },
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "])\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/val', \n",
    "                                                transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY9fV1CYVsX-"
   },
   "outputs": [],
   "source": [
    "test_batch_gen = torch.utils.data.DataLoader(test_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HrVQEkwCVsYA",
    "outputId": "b1b9c684-8f75-4c96-85a7-563684afc418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t9.00 %\n",
      "We need more magic! Follow instructons below\n"
     ]
    }
   ],
   "source": [
    "model.train(False) # disable dropout / use averages for batch_norm\n",
    "test_batch_acc = []\n",
    "for X_batch, y_batch in test_batch_gen:\n",
    "    logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "    y_pred = logits.max(1)[1].data\n",
    "    test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "\n",
    "test_accuracy = np.mean(test_batch_acc)\n",
    "    \n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 70:\n",
    "    print(\"U'r freakin' amazin'!\")\n",
    "elif test_accuracy * 100 > 50:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 40:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 30:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 20:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOvofvSMVsYC"
   },
   "source": [
    "#### Now let's try simple CNN with BN<br> And make function for fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUrAFZV-p4k2"
   },
   "outputs": [],
   "source": [
    "def compute_loss_model(model,X_batch, y_batch):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()\n",
    "    y_batch = Variable(torch.LongTensor(y_batch)).cuda()\n",
    "    logits = model.cuda()(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nXTUOjgVsYD"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from torchsummary import summary\n",
    "\n",
    "def fit(model, train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen, optim=torch.optim.SGD, num_epochs=15,  lr=1e-2, batch_size=50):\n",
    "\n",
    "    opt = optim(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    flag = 0\n",
    "    all_val_accuracy = [0,0]\n",
    "    max_accuracy = 0\n",
    "    \n",
    "    flag_changes = 0\n",
    "    print(num_epochs)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        start_time = time.time()\n",
    "        model.train(True) # enable dropout / batch_norm training behavior\n",
    "        for (X_batch, y_batch) in train_batch_gen:\n",
    "            # train on batch\n",
    "            loss = compute_loss_model(model,X_batch, y_batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            train_loss.append(loss.data.cpu().numpy())  \n",
    "        model.train(False) # disable dropout / use averages for batch_norm\n",
    "        for X_batch, y_batch in val_batch_gen:\n",
    "            logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "            y_pred = logits.max(1)[1].data\n",
    "            val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "    \n",
    "        print (epoch)\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))\n",
    "        all_val_accuracy.append(np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100)\n",
    "        \n",
    "        # earling-stop step\n",
    "        if max(all_val_accuracy) > max_accuracy: \n",
    "            max_accuracy = max(all_val_accuracy)\n",
    "            flag = 0\n",
    "        else:\n",
    "            flag += 1\n",
    "        if(flag == 10):\n",
    "            break\n",
    "            \n",
    "        if all_val_accuracy[-1]<all_val_accuracy[-2]:\n",
    "            if flag_changes >5:\n",
    "                break\n",
    "            flag_changes+=1\n",
    "        else:\n",
    "            flag_changes = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBLa7vb0VsYF"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_batch_gen,train_accuracy=False):\n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    test_batch_acc = []\n",
    "    for X_batch, y_batch in test_batch_gen:\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Final results:\")\n",
    "    if train_accuracy:\n",
    "        test_accuracy = np.mean(test_batch_acc[-len(train_dataset) // batch_size :])\n",
    "        print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_accuracy * 100))\n",
    "        \n",
    "    else:\n",
    "        test_accuracy = np.mean(test_batch_acc)\n",
    "        print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_accuracy * 100))\n",
    "\n",
    "    if test_accuracy * 100 > 40:\n",
    "        print(\"full points U'r freakin' amazin'!\")\n",
    "    elif test_accuracy * 100 > 37.5:\n",
    "        print(\"Achievement unlocked: 90lvl Warlock!\")\n",
    "    elif test_accuracy * 100 > 35:\n",
    "        print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "    elif test_accuracy * 100 > 32.5:\n",
    "        print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "    elif test_accuracy * 100 > 30:\n",
    "        print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "    elif test_accuracy * 100 > 25:\n",
    "        print(\"Achievement unlocked: 50lvl Warlock!\")\n",
    "    else:\n",
    "        print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtko6PlcVsYJ"
   },
   "outputs": [],
   "source": [
    "def simple_cnn():\n",
    "    model = nn.Sequential()\n",
    "    model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding = (1, 1)))\n",
    "    model.add_module('norm1', nn.BatchNorm2d(64))\n",
    "    model.add_module('relu1', nn.ReLU())\n",
    "    model.add_module('pool1', nn.MaxPool2d(2))\n",
    "\n",
    "    model.add_module('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding = (1,1)))\n",
    "    model.add_module('norm2', nn.BatchNorm2d(128))\n",
    "    model.add_module('relu2', nn.ReLU())\n",
    "    model.add_module('pool2', nn.MaxPool2d(2))\n",
    "\n",
    "    model.add_module('flat', Flatten())\n",
    "    model.add_module('dense2', nn.Linear(128*16*16, 1024))\n",
    "    model.add_module('norm__2', nn.BatchNorm1d(1024))\n",
    "    model.add_module('relu2', nn.ReLU())\n",
    "    model.add_module('dropout', nn.Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add_module('dense1_logits', nn.Linear(1024, 200)) # logits for 200 classes\n",
    "    model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "tcLxtjA8VsYQ",
    "outputId": "a76a6bcd-296d-437d-a889-5f7e1bf9dd20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5          [-1, 128, 32, 32]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 32, 32]             256\n",
      "              ReLU-7          [-1, 128, 32, 32]               0\n",
      "         MaxPool2d-8          [-1, 128, 16, 16]               0\n",
      "           Flatten-9                [-1, 32768]               0\n",
      "           Linear-10                 [-1, 1024]      33,555,456\n",
      "      BatchNorm1d-11                 [-1, 1024]           2,048\n",
      "          Dropout-12                 [-1, 1024]               0\n",
      "           Linear-13                  [-1, 200]         205,000\n",
      "================================================================\n",
      "Total params: 33,838,536\n",
      "Trainable params: 33,838,536\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 10.02\n",
      "Params size (MB): 129.08\n",
      "Estimated Total Size (MB): 139.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "simple_cnn_model = simple_cnn()\n",
    "\n",
    "summary(simple_cnn_model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "colab_type": "code",
    "id": "72GZQMLuwjJj",
    "outputId": "be6c3e5a-aa1c-4aa4-8410-b439249e1c75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1/15 [01:02<14:39, 62.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 15 took 62.845s\n",
      "  training loss (in-iteration): \t4.511542\n",
      "  validation accuracy: \t\t\t15.96 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2/15 [02:05<13:37, 62.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 15 took 62.969s\n",
      "  training loss (in-iteration): \t3.971709\n",
      "  validation accuracy: \t\t\t11.21 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 3/15 [03:09<12:36, 63.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 15 took 63.387s\n",
      "  training loss (in-iteration): \t3.669898\n",
      "  validation accuracy: \t\t\t19.92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 4/15 [04:13<11:38, 63.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 15 took 64.469s\n",
      "  training loss (in-iteration): \t3.327875\n",
      "  validation accuracy: \t\t\t22.12 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 5/15 [05:16<10:33, 63.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 15 took 63.039s\n",
      "  training loss (in-iteration): \t2.856931\n",
      "  validation accuracy: \t\t\t21.60 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 6/15 [06:19<09:28, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 6 of 15 took 62.818s\n",
      "  training loss (in-iteration): \t2.278643\n",
      "  validation accuracy: \t\t\t20.35 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 7/15 [07:22<08:24, 63.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 7 of 15 took 62.961s\n",
      "  training loss (in-iteration): \t1.760238\n",
      "  validation accuracy: \t\t\t19.68 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 8/15 [08:26<07:23, 63.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 8 of 15 took 63.829s\n",
      "  training loss (in-iteration): \t1.417063\n",
      "  validation accuracy: \t\t\t18.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 9/15 [09:29<06:19, 63.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 9 of 15 took 63.250s\n",
      "  training loss (in-iteration): \t1.237917\n",
      "  validation accuracy: \t\t\t17.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 10/15 [10:32<05:15, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 10 of 15 took 62.886s\n",
      "  training loss (in-iteration): \t1.120424\n",
      "  validation accuracy: \t\t\t17.75 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-91962f8f8d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_cnn_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_batch_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batch_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batch_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-7c8c17082eb9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_batch_gen, val_batch_gen, optim, num_epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# disable dropout / use averages for batch_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_batch_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(simple_cnn_model,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_EKRxvxpxcYa"
   },
   "outputs": [],
   "source": [
    "simple_cnn_model = simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "8cTtGqEWVsYS",
    "outputId": "c9e86861-6b9e-41d6-e7ca-ce84bf21e029"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|██        | 1/5 [01:03<04:14, 63.59s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 5 took 63.592s\n",
      "  training loss (in-iteration): \t4.509953\n",
      "  validation accuracy: \t\t\t11.10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|████      | 2/5 [02:06<03:10, 63.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 5 took 63.161s\n",
      "  training loss (in-iteration): \t3.963488\n",
      "  validation accuracy: \t\t\t18.50 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|██████    | 3/5 [03:09<02:06, 63.32s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 5 took 62.960s\n",
      "  training loss (in-iteration): \t3.682571\n",
      "  validation accuracy: \t\t\t19.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|████████  | 4/5 [04:13<01:03, 63.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 5 took 63.587s\n",
      "  training loss (in-iteration): \t3.367103\n",
      "  validation accuracy: \t\t\t20.68 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 5/5 [05:16<00:00, 63.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 5 took 63.079s\n",
      "  training loss (in-iteration): \t2.961023\n",
      "  validation accuracy: \t\t\t21.70 %\n"
     ]
    }
   ],
   "source": [
    "fit(simple_cnn_model,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "H2vhvP9TVsYU",
    "outputId": "768fa318-47cb-49ca-81d0-cd0363106656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(simple_cnn_model, 'simple_cnn_model.ckpt')\n",
    "torch.save(simple_cnn_model.state_dict(), 'simple_cnn_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "JJh4nDubVsYX",
    "outputId": "e2ad0c6e-b96d-423e-a3cc-80475d0dff92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t21.07 %\n",
      "Achievement unlocked: 60lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "predict(simple_cnn_model,test_batch_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxcz3mLwyosn"
   },
   "source": [
    "### But it's not enough let's make another type of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WpnCR31iVsYZ"
   },
   "source": [
    "### Let's try VGG-like CNN: (it was mentioned in many papers)\n",
    "\n",
    "* [1](http://cs231n.stanford.edu/reports/2017/posters/931.pdf)\n",
    "* [2](http://cs231n.stanford.edu/reports/2017/pdfs/940.pdf)\n",
    "* [3](https://neurohive.io/en/popular-networks/vgg16/) picture from here\n",
    "* [4](https://www3.cs.stonybrook.edu/~zekzhang/cnn_classifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHC_HxuJxzim"
   },
   "source": [
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/Capture-564x570.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YOzuIaPxzin"
   },
   "source": [
    "#### Firstly, I would like to make model like vgg16(D) without 2 last consistent layers(512 & 512) because <br> many VGG models which worked on ImageNet dataset have final picture shape (8*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rk00_sDJVsYZ"
   },
   "outputs": [],
   "source": [
    "def vgg_3_conv():\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    model.add_module('conv1_1', nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm1_1', nn.BatchNorm2d(64))\n",
    "    model.add_module('relu1_1', nn.ReLU())\n",
    "    model.add_module('conv1_2', nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm1_2', nn.BatchNorm2d(64))\n",
    "    model.add_module('relu1_2', nn.ReLU())\n",
    "    model.add_module('pool1', nn.MaxPool2d(2))#64*32*32\n",
    "\n",
    "    model.add_module('conv2_1', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm2_1', nn.BatchNorm2d(128))\n",
    "    model.add_module('relu2_1', nn.ReLU())\n",
    "    model.add_module('conv2_2', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm2_2', nn.BatchNorm2d(128))\n",
    "    model.add_module('relu2_2', nn.ReLU())\n",
    "    model.add_module('pool2', nn.MaxPool2d(2))#128*16*16\n",
    "    \n",
    "    model.add_module('conv3_1', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm3_1', nn.BatchNorm2d(256))\n",
    "    model.add_module('relu3_1', nn.ReLU())\n",
    "    model.add_module('conv3_2', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm3_2', nn.BatchNorm2d(256))\n",
    "    model.add_module('relu3_2', nn.ReLU())\n",
    "    model.add_module('conv3_3', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm3_3', nn.BatchNorm2d(256))\n",
    "    model.add_module('relu3_3', nn.ReLU())\n",
    "    model.add_module('pool3', nn.MaxPool2d(2))#256*8*8\n",
    "    \n",
    "    \n",
    "\n",
    "    model.add_module('flat', Flatten())\n",
    "    model.add_module('dense3', nn.Linear(16384, 2048))\n",
    "    model.add_module('norm__3', nn.BatchNorm1d(2048))\n",
    "    model.add_module('relu__3', nn.ReLU())\n",
    "    model.add_module('dropout3', nn.Dropout(0.5))\n",
    "    \n",
    "    model.add_module('dense2', nn.Linear(2048, 1024))\n",
    "    model.add_module('norm__2', nn.BatchNorm1d(1024))\n",
    "    model.add_module('relu__2', nn.ReLU())\n",
    "    model.add_module('dropout2', nn.Dropout(0.5))\n",
    "    #was without\n",
    "\n",
    "    model.add_module('dense1_logits', nn.Linear(1024, 200)) # logits for 200 classes\n",
    "    model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "K1_guoz02t8b",
    "outputId": "f1b43479-c09d-4abc-dd71-c55228eb3a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "            Conv2d-4           [-1, 64, 64, 64]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 64, 64]             128\n",
      "              ReLU-6           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 32, 32]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 32, 32]             256\n",
      "             ReLU-10          [-1, 128, 32, 32]               0\n",
      "           Conv2d-11          [-1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "             ReLU-13          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-14          [-1, 128, 16, 16]               0\n",
      "           Conv2d-15          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 16, 16]             512\n",
      "             ReLU-17          [-1, 256, 16, 16]               0\n",
      "           Conv2d-18          [-1, 256, 16, 16]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 16, 16]             512\n",
      "             ReLU-20          [-1, 256, 16, 16]               0\n",
      "           Conv2d-21          [-1, 256, 16, 16]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 16, 16]             512\n",
      "             ReLU-23          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-24            [-1, 256, 8, 8]               0\n",
      "          Flatten-25                [-1, 16384]               0\n",
      "           Linear-26                 [-1, 2048]      33,556,480\n",
      "      BatchNorm1d-27                 [-1, 2048]           4,096\n",
      "             ReLU-28                 [-1, 2048]               0\n",
      "          Dropout-29                 [-1, 2048]               0\n",
      "           Linear-30                 [-1, 1024]       2,098,176\n",
      "      BatchNorm1d-31                 [-1, 1024]           2,048\n",
      "             ReLU-32                 [-1, 1024]               0\n",
      "           Linear-33                  [-1, 200]         205,000\n",
      "================================================================\n",
      "Total params: 37,603,592\n",
      "Trainable params: 37,603,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 23.59\n",
      "Params size (MB): 143.45\n",
      "Estimated Total Size (MB): 167.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_vgg_3 = vgg_3_conv()\n",
    "\n",
    "summary(model_vgg_3, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2074
    },
    "colab_type": "code",
    "id": "ECYtoQbGVsYb",
    "outputId": "28b37d1a-2173-4a0c-c26e-3f28f8b6fa62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 1/15 [03:41<51:39, 221.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 15 took 221.387s\n",
      "  training loss (in-iteration): \t4.873892\n",
      "  validation accuracy: \t\t\t7.52 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 2/15 [07:20<47:50, 220.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 15 took 219.386s\n",
      "  training loss (in-iteration): \t4.094277\n",
      "  validation accuracy: \t\t\t15.68 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 3/15 [10:59<44:00, 220.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 15 took 218.244s\n",
      "  training loss (in-iteration): \t3.643180\n",
      "  validation accuracy: \t\t\t17.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 4/15 [14:37<40:13, 219.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 15 took 217.972s\n",
      "  training loss (in-iteration): \t3.376798\n",
      "  validation accuracy: \t\t\t24.31 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 5/15 [18:14<36:27, 218.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 15 took 217.054s\n",
      "  training loss (in-iteration): \t3.148226\n",
      "  validation accuracy: \t\t\t27.05 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 6/15 [21:49<32:40, 217.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 6 of 15 took 215.911s\n",
      "  training loss (in-iteration): \t2.923218\n",
      "  validation accuracy: \t\t\t29.88 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 7/15 [25:25<28:57, 217.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 7 of 15 took 215.540s\n",
      "  training loss (in-iteration): \t2.686039\n",
      "  validation accuracy: \t\t\t31.05 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 8/15 [29:00<25:16, 216.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 8 of 15 took 215.211s\n",
      "  training loss (in-iteration): \t2.430439\n",
      "  validation accuracy: \t\t\t31.92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 9/15 [32:35<21:37, 216.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 9 of 15 took 215.201s\n",
      "  training loss (in-iteration): \t2.154887\n",
      "  validation accuracy: \t\t\t32.23 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 10/15 [36:11<17:59, 215.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 10 of 15 took 215.062s\n",
      "  training loss (in-iteration): \t1.885117\n",
      "  validation accuracy: \t\t\t32.87 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 11/15 [39:46<14:22, 215.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 11 of 15 took 215.002s\n",
      "  training loss (in-iteration): \t1.623405\n",
      "  validation accuracy: \t\t\t32.16 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 12/15 [43:21<10:46, 215.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 12 of 15 took 214.975s\n",
      "  training loss (in-iteration): \t1.404879\n",
      "  validation accuracy: \t\t\t31.87 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 13/15 [46:56<07:10, 215.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 13 of 15 took 215.086s\n",
      "  training loss (in-iteration): \t1.211562\n",
      "  validation accuracy: \t\t\t32.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 14/15 [50:31<03:35, 215.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 14 of 15 took 215.004s\n",
      "  training loss (in-iteration): \t1.054120\n",
      "  validation accuracy: \t\t\t30.38 %\n",
      "14\n",
      "Epoch 15 of 15 took 215.040s\n",
      "  training loss (in-iteration): \t0.922970\n",
      "  validation accuracy: \t\t\t31.37 %\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_3,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "A3XyDb-MAMg3",
    "outputId": "8f9c8713-1a8b-440f-e208-8fd91eeaa592",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t31.90 %\n",
      "Achievement unlocked: 70lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_3,test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rf-Nwx9xziz"
   },
   "outputs": [],
   "source": [
    "predict(model_vgg_3, train_batch_gen,train_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gn1q5FQ_xzi0"
   },
   "source": [
    "#### Let's try more epoch <br>may be it will exit from plato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "PfMNPzvgEP1Q",
    "outputId": "5790785b-0c8f-42bd-f9d1-ee50c7c81399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [03:36<14:24, 216.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 5 took 216.110s\n",
      "  training loss (in-iteration): \t0.837569\n",
      "  validation accuracy: \t\t\t30.99 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [07:11<10:47, 215.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 5 took 215.033s\n",
      "  training loss (in-iteration): \t0.740992\n",
      "  validation accuracy: \t\t\t31.26 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [10:46<07:11, 215.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 5 took 214.938s\n",
      "  training loss (in-iteration): \t0.672289\n",
      "  validation accuracy: \t\t\t30.54 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [14:21<03:35, 215.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 5 took 214.914s\n",
      "  training loss (in-iteration): \t0.614868\n",
      "  validation accuracy: \t\t\t30.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [17:56<00:00, 215.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 5 took 215.013s\n",
      "  training loss (in-iteration): \t0.559078\n",
      "  validation accuracy: \t\t\t31.30 %\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_3,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8aVrxfRMEjUq",
    "outputId": "73595aab-ab55-4642-d9da-372b24d38d2d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t32.18 %\n",
      "Achievement unlocked: 70lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_3,test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crPNHWABxzi7"
   },
   "outputs": [],
   "source": [
    "predict(model_vgg_3, train_batch_gen,train_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spDqmZr9xzi9"
   },
   "outputs": [],
   "source": [
    "torch.save(model_vgg_3, 'model_vgg_3_20.ckpt')\n",
    "torch.save(model_vgg_3.state_dict(), 'model_vgg_3_20_params.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uB_9GgPBxzjD"
   },
   "source": [
    "#### Despite val accuracy oscillates from one epoch to another <br> Our test accuracy increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "bPdXWjuTJo67",
    "outputId": "14b208a7-9260-495f-ddfa-59ed05d25529"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [03:35<14:20, 215.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 5 took 215.182s\n",
      "  training loss (in-iteration): \t0.550353\n",
      "  validation accuracy: \t\t\t30.36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [07:10<10:45, 215.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 5 took 214.998s\n",
      "  training loss (in-iteration): \t0.500117\n",
      "  validation accuracy: \t\t\t30.78 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [10:45<07:10, 215.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 5 took 215.061s\n",
      "  training loss (in-iteration): \t0.458434\n",
      "  validation accuracy: \t\t\t31.20 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [14:20<03:35, 215.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 5 took 214.884s\n",
      "  training loss (in-iteration): \t0.441444\n",
      "  validation accuracy: \t\t\t31.40 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [17:55<00:00, 215.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 5 took 215.015s\n",
      "  training loss (in-iteration): \t0.419600\n",
      "  validation accuracy: \t\t\t29.89 %\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_3,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8Z9dfhfhJsir",
    "outputId": "597b79c3-8c04-4250-ea72-4bd03749784a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t30.29 %\n",
      "Achievement unlocked: 70lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_3,test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-0izpdBxzjN"
   },
   "outputs": [],
   "source": [
    "predict(model_vgg_3, train_batch_gen,train_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "DlLB8fJtVsYd",
    "outputId": "15fcff3e-4b7a-415e-d5ba-c615b297254c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_vgg_3, 'model_vgg_3.ckpt')\n",
    "torch.save(model_vgg_3.state_dict(), 'model_vgg_3.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcYQg_04xzjR"
   },
   "source": [
    "### There is no point in continuing. Let's try new model\n",
    "\n",
    "### Model will be also VGG16-like(D) but without last consistent layer (512).<br> I suppose that CNN will have problem to train with image shape 2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yONO1Nr7AZu_"
   },
   "outputs": [],
   "source": [
    "def vgg_4_conv():\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    model.add_module('conv1_1', nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm1_1', nn.BatchNorm2d(64))\n",
    "    model.add_module('relu1_1', nn.ReLU())\n",
    "    model.add_module('conv1_2', nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm1_2', nn.BatchNorm2d(64))\n",
    "    model.add_module('relu1_2', nn.ReLU())\n",
    "    model.add_module('pool1', nn.MaxPool2d(2))#64*32*32\n",
    "\n",
    "    model.add_module('conv2_1', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm2_1', nn.BatchNorm2d(128))\n",
    "    model.add_module('relu2_1', nn.ReLU())\n",
    "    model.add_module('conv2_2', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm2_2', nn.BatchNorm2d(128))\n",
    "    model.add_module('relu2_2', nn.ReLU())\n",
    "    model.add_module('pool2', nn.MaxPool2d(2))#128*16*16\n",
    "    \n",
    "    model.add_module('conv3_1', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm3_1', nn.BatchNorm2d(256))\n",
    "    model.add_module('relu3_1', nn.ReLU())\n",
    "    model.add_module('conv3_2', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm3_2', nn.BatchNorm2d(256))\n",
    "    model.add_module('relu3_2', nn.ReLU())\n",
    "    model.add_module('conv3_3', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm3_3', nn.BatchNorm2d(256))\n",
    "    model.add_module('relu3_3', nn.ReLU())\n",
    "    model.add_module('pool3', nn.MaxPool2d(2))#256*8*8\n",
    "    \n",
    "    model.add_module('conv4_1', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm4_1', nn.BatchNorm2d(512))\n",
    "    model.add_module('relu4_1', nn.ReLU())\n",
    "    model.add_module('conv4_2', nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm4_2', nn.BatchNorm2d(512))\n",
    "    model.add_module('relu4_2', nn.ReLU())\n",
    "    model.add_module('conv4_3', nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding = 1))\n",
    "    model.add_module('norm4_3', nn.BatchNorm2d(512))\n",
    "    model.add_module('relu4_3', nn.ReLU())\n",
    "    model.add_module('pool4', nn.MaxPool2d(2))#512*4*4\n",
    "\n",
    "    model.add_module('flat', Flatten())\n",
    "    model.add_module('dense3', nn.Linear(512*4*4, 512*4))\n",
    "    model.add_module('norm__3', nn.BatchNorm1d(512*4))\n",
    "    model.add_module('relu__3', nn.ReLU())\n",
    "    model.add_module('dropout', nn.Dropout(0.5))\n",
    "    \n",
    "    model.add_module('dense2', nn.Linear(512*4, 1024))\n",
    "    model.add_module('norm__2', nn.BatchNorm1d(1024))\n",
    "    model.add_module('relu__2', nn.ReLU())\n",
    "#     model.add_module('dropout', nn.Dropout(0.5))\n",
    "    \n",
    "\n",
    "    model.add_module('dense1_logits', nn.Linear(1024, 200)) # logits for 200 classes\n",
    "    model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "3bFo424pAZx3",
    "outputId": "b74be7e3-f60c-43e2-c173-757fcd4fd298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "            Conv2d-4           [-1, 64, 64, 64]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 64, 64]             128\n",
      "              ReLU-6           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 32, 32]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 32, 32]             256\n",
      "             ReLU-10          [-1, 128, 32, 32]               0\n",
      "           Conv2d-11          [-1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "             ReLU-13          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-14          [-1, 128, 16, 16]               0\n",
      "           Conv2d-15          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 16, 16]             512\n",
      "             ReLU-17          [-1, 256, 16, 16]               0\n",
      "           Conv2d-18          [-1, 256, 16, 16]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 16, 16]             512\n",
      "             ReLU-20          [-1, 256, 16, 16]               0\n",
      "           Conv2d-21          [-1, 256, 16, 16]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 16, 16]             512\n",
      "             ReLU-23          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-24            [-1, 256, 8, 8]               0\n",
      "           Conv2d-25            [-1, 512, 8, 8]       1,180,160\n",
      "      BatchNorm2d-26            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-27            [-1, 512, 8, 8]               0\n",
      "           Conv2d-28            [-1, 512, 8, 8]       2,359,808\n",
      "      BatchNorm2d-29            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-30            [-1, 512, 8, 8]               0\n",
      "           Conv2d-31            [-1, 512, 8, 8]       2,359,808\n",
      "      BatchNorm2d-32            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-33            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-34            [-1, 512, 4, 4]               0\n",
      "          Flatten-35                 [-1, 8192]               0\n",
      "           Linear-36                 [-1, 2048]      16,779,264\n",
      "      BatchNorm1d-37                 [-1, 2048]           4,096\n",
      "             ReLU-38                 [-1, 2048]               0\n",
      "          Dropout-39                 [-1, 2048]               0\n",
      "           Linear-40                 [-1, 1024]       2,098,176\n",
      "      BatchNorm1d-41                 [-1, 1024]           2,048\n",
      "             ReLU-42                 [-1, 1024]               0\n",
      "           Linear-43                  [-1, 200]         205,000\n",
      "================================================================\n",
      "Total params: 26,729,224\n",
      "Trainable params: 26,729,224\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 25.84\n",
      "Params size (MB): 101.96\n",
      "Estimated Total Size (MB): 127.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_vgg_4 = vgg_4_conv()\n",
    "\n",
    "summary(model_vgg_4, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "tDzpSSJHAZ0a",
    "outputId": "765be7cb-ea22-4143-aa98-455955d5167c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1/15 [04:11<58:38, 251.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 15 took 251.339s\n",
      "  training loss (in-iteration): \t4.458200\n",
      "  validation accuracy: \t\t\t15.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2/15 [08:29<54:52, 253.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 15 took 257.797s\n",
      "  training loss (in-iteration): \t3.564189\n",
      "  validation accuracy: \t\t\t22.86 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 3/15 [12:47<50:57, 254.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 15 took 258.204s\n",
      "  training loss (in-iteration): \t3.132055\n",
      "  validation accuracy: \t\t\t29.72 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 4/15 [17:05<46:54, 255.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 15 took 258.325s\n",
      "  training loss (in-iteration): \t2.819005\n",
      "  validation accuracy: \t\t\t33.34 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 5/15 [21:23<42:45, 256.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 15 took 258.226s\n",
      "  training loss (in-iteration): \t2.576796\n",
      "  validation accuracy: \t\t\t37.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 6/15 [25:42<38:34, 257.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 6 of 15 took 258.546s\n",
      "  training loss (in-iteration): \t2.375805\n",
      "  validation accuracy: \t\t\t40.72 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 7/15 [30:00<34:19, 257.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 7 of 15 took 258.249s\n",
      "  training loss (in-iteration): \t2.192314\n",
      "  validation accuracy: \t\t\t41.89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 8/15 [34:19<30:04, 257.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 8 of 15 took 258.411s\n",
      "  training loss (in-iteration): \t2.028504\n",
      "  validation accuracy: \t\t\t42.63 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 9/15 [38:37<25:47, 257.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 9 of 15 took 258.085s\n",
      "  training loss (in-iteration): \t1.877708\n",
      "  validation accuracy: \t\t\t44.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 10/15 [42:55<21:29, 257.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 10 of 15 took 258.259s\n",
      "  training loss (in-iteration): \t1.727335\n",
      "  validation accuracy: \t\t\t45.98 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 11/15 [47:13<17:12, 258.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 11 of 15 took 258.144s\n",
      "  training loss (in-iteration): \t1.583926\n",
      "  validation accuracy: \t\t\t47.16 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 12/15 [51:31<12:54, 258.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 12 of 15 took 258.150s\n",
      "  training loss (in-iteration): \t1.444984\n",
      "  validation accuracy: \t\t\t46.58 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 13/15 [55:50<08:36, 258.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 13 of 15 took 258.271s\n",
      "  training loss (in-iteration): \t1.313184\n",
      "  validation accuracy: \t\t\t47.36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 14/15 [1:00:08<04:18, 258.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 14 of 15 took 258.138s\n",
      "  training loss (in-iteration): \t1.180415\n",
      "  validation accuracy: \t\t\t47.43 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 15/15 [1:04:26<00:00, 258.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 15 of 15 took 258.256s\n",
      "  training loss (in-iteration): \t1.051286\n",
      "  validation accuracy: \t\t\t46.07 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_4,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Dv8aJci2AZ5Y",
    "outputId": "69f0d139-b687-45cd-a683-05efb6cdaa67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_vgg_4, 'model_vgg_4_15.ckpt')\n",
    "torch.save(model_vgg_4.state_dict(), 'model_vgg_4_15_dict.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "hgEwHfSeAZ8S",
    "outputId": "f5b72a62-0d48-4863-a0aa-f6442ca8cd31",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t45.73 %\n",
      "full points U'r freakin' amazin'!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4,test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "LHwGYfCCxzjg",
    "outputId": "de525fc5-3206-4f1d-fbbb-f8e1b8f51717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  train accuracy:\t\t80.78 %\n",
      "full points U'r freakin' amazin'!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4, train_batch_gen,train_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVqYaRT8xzjj"
   },
   "source": [
    "#### The model took necessary points but try to increase her accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "zA6VsFdk4-d_",
    "outputId": "d9e47ecb-a4c3-4ca7-ccd7-18104610c84f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [04:11<16:44, 251.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 5 took 251.074s\n",
      "  training loss (in-iteration): \t0.937667\n",
      "  validation accuracy: \t\t\t48.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [08:28<12:38, 252.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 5 took 257.361s\n",
      "  training loss (in-iteration): \t0.826441\n",
      "  validation accuracy: \t\t\t47.03 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [12:46<08:28, 254.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 5 took 258.038s\n",
      "  training loss (in-iteration): \t0.719867\n",
      "  validation accuracy: \t\t\t45.55 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [17:04<04:15, 255.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 5 took 257.807s\n",
      "  training loss (in-iteration): \t0.639638\n",
      "  validation accuracy: \t\t\t46.85 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [21:22<00:00, 256.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 5 took 257.955s\n",
      "  training loss (in-iteration): \t0.559397\n",
      "  validation accuracy: \t\t\t47.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_4,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam,lr=1e-4,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "iW14TqJa4-hf",
    "outputId": "acab6783-093c-4a03-c67c-444b0f01e6fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t47.27 %\n",
      "full points U'r freakin' amazin'!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4,test_batch_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbfPDnsnxzjo"
   },
   "source": [
    "predict(model_vgg_4, train_batch_gen,train_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HNBGDat0GtDt",
    "outputId": "9857c21a-dbb7-4652-b617-c3b2f46e71f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  train accuracy:\t\t93.92 %\n",
      "full points U'r freakin' amazin'!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4, train_batch_gen,train_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuJAV-9uxzjp"
   },
   "source": [
    "#### Let's try more epoch, may be it will increase test accuracy despite reduction of val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "QGmCPSaE4-k_",
    "outputId": "679f0f85-799f-4d61-c96b-5d750ab6728c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [04:18<17:12, 258.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 5 took 258.033s\n",
      "  training loss (in-iteration): \t0.512136\n",
      "  validation accuracy: \t\t\t46.56 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [08:35<12:53, 257.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 5 took 257.839s\n",
      "  training loss (in-iteration): \t0.441928\n",
      "  validation accuracy: \t\t\t46.19 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [12:53<08:35, 257.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 5 took 257.701s\n",
      "  training loss (in-iteration): \t0.395127\n",
      "  validation accuracy: \t\t\t46.62 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [17:11<04:17, 257.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 5 took 257.773s\n",
      "  training loss (in-iteration): \t0.356969\n",
      "  validation accuracy: \t\t\t46.74 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [21:29<00:00, 257.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 5 took 257.843s\n",
      "  training loss (in-iteration): \t0.322891\n",
      "  validation accuracy: \t\t\t46.85 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_4,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adam,lr=1e-4,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "g0-pGOYh4-od",
    "outputId": "c9448db3-6a04-451c-e81a-9098754394fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t45.96 %\n",
      "full points U'r freakin' amazin'!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4,test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fFxOLgGec8tL",
    "outputId": "4afc9e92-aff9-476a-b075-a99b5263e652",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t45.96 %\n",
      "full points U'r freakin' amazin'!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4,test_batch_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see model_vgg_4 has the maximum of test accuracy 47.27 <br> and after 25 epoch our train approximately 99% that'is why it will not give better quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxh9WK1FN-G4"
   },
   "source": [
    "### Let's try final model without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGQBUaBON-J2"
   },
   "outputs": [],
   "source": [
    "dataset1 = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transforms.ToTensor())\n",
    "test_dataset1 = torchvision.datasets.ImageFolder('tiny-imagenet-200/val', transform=transforms.ToTensor())\n",
    "train_dataset1, val_dataset1 = torch.utils.data.random_split(dataset, [80000, 20000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAnEv9kJN-Lw"
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_batch_gen1 = torch.utils.data.DataLoader(train_dataset1, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_p80vQjN-RR"
   },
   "outputs": [],
   "source": [
    "val_batch_gen1 = torch.utils.data.DataLoader(val_dataset1, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvDm-7gjxzj2"
   },
   "outputs": [],
   "source": [
    "test_batch_gen1 = torch.utils.data.DataLoader(test_dataset1, \n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBnr-qimxzj3"
   },
   "outputs": [],
   "source": [
    "model_vgg_4 = vgg_4_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "J43OmZUjxzj4",
    "outputId": "987970ad-9e30-4731-9a81-3500ae12208e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1/15 [04:13<59:12, 253.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 15 took 253.740s\n",
      "  training loss (in-iteration): \t4.437639\n",
      "  validation accuracy: \t\t\t16.30 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2/15 [08:31<55:14, 254.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 15 took 257.731s\n",
      "  training loss (in-iteration): \t3.536462\n",
      "  validation accuracy: \t\t\t23.95 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 3/15 [12:49<51:10, 255.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 15 took 257.960s\n",
      "  training loss (in-iteration): \t3.106857\n",
      "  validation accuracy: \t\t\t30.75 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 4/15 [17:07<47:02, 256.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 15 took 258.263s\n",
      "  training loss (in-iteration): \t2.805357\n",
      "  validation accuracy: \t\t\t33.35 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 5/15 [21:26<42:51, 257.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 15 took 258.400s\n",
      "  training loss (in-iteration): \t2.563449\n",
      "  validation accuracy: \t\t\t37.51 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 6/15 [25:44<38:36, 257.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 6 of 15 took 258.160s\n",
      "  training loss (in-iteration): \t2.362634\n",
      "  validation accuracy: \t\t\t38.72 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 7/15 [30:02<34:21, 257.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 7 of 15 took 258.199s\n",
      "  training loss (in-iteration): \t2.184224\n",
      "  validation accuracy: \t\t\t40.91 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 8/15 [34:20<30:04, 257.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 8 of 15 took 258.065s\n",
      "  training loss (in-iteration): \t2.021948\n",
      "  validation accuracy: \t\t\t42.99 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 9/15 [38:38<25:47, 257.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 9 of 15 took 258.220s\n",
      "  training loss (in-iteration): \t1.867450\n",
      "  validation accuracy: \t\t\t44.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 10/15 [42:56<21:30, 258.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 10 of 15 took 258.228s\n",
      "  training loss (in-iteration): \t1.721002\n",
      "  validation accuracy: \t\t\t44.81 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 11/15 [47:15<17:12, 258.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 11 of 15 took 258.158s\n",
      "  training loss (in-iteration): \t1.574139\n",
      "  validation accuracy: \t\t\t45.52 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 12/15 [51:33<12:54, 258.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 12 of 15 took 258.025s\n",
      "  training loss (in-iteration): \t1.434782\n",
      "  validation accuracy: \t\t\t45.85 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 13/15 [55:51<08:36, 258.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 13 of 15 took 257.899s\n",
      "  training loss (in-iteration): \t1.300968\n",
      "  validation accuracy: \t\t\t46.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 14/15 [1:00:09<04:18, 258.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 14 of 15 took 258.221s\n",
      "  training loss (in-iteration): \t1.165500\n",
      "  validation accuracy: \t\t\t45.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 15/15 [1:04:27<00:00, 258.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 15 of 15 took 257.909s\n",
      "  training loss (in-iteration): \t1.038347\n",
      "  validation accuracy: \t\t\t46.23 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_4,train_batch_gen=train_batch_gen1, val_batch_gen=val_batch_gen1,optim=torch.optim.Adam,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9eHFMR_Exzj5",
    "outputId": "71e4b398-df30-4e0b-acab-d96f8ed20728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t46.27 %\n",
      "full points U'r freakin' amazin'!\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4,test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ZOc63bS3VB7q",
    "outputId": "5e000992-6e33-4794-fa3d-77737dda6a82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_vgg_4, 'model_vgg_4_15_non_augmentation.ckpt')\n",
    "torch.save(model_vgg_4.state_dict(), 'model_vgg_4_15_dict_non_augmentation.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnsrK5yixzj7"
   },
   "source": [
    "### Let's try different optimizators for final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEEm4giAxzkA"
   },
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zL336b-LxzkA"
   },
   "outputs": [],
   "source": [
    "model_vgg_4 = vgg_4_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "1pGNn4stxzkC",
    "outputId": "be43cf6e-c4a1-4e0d-eaaa-990fcd6b2850"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1/15 [04:12<59:01, 253.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1 of 15 took 252.994s\n",
      "  training loss (in-iteration): \t5.190955\n",
      "  validation accuracy: \t\t\t4.76 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2/15 [08:26<54:51, 253.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 2 of 15 took 253.583s\n",
      "  training loss (in-iteration): \t5.065718\n",
      "  validation accuracy: \t\t\t5.78 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 3/15 [12:40<50:39, 253.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 3 of 15 took 253.680s\n",
      "  training loss (in-iteration): \t4.995880\n",
      "  validation accuracy: \t\t\t6.40 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 4/15 [16:53<46:27, 253.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 4 of 15 took 253.646s\n",
      "  training loss (in-iteration): \t4.944571\n",
      "  validation accuracy: \t\t\t6.75 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 5/15 [21:07<42:15, 253.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 5 of 15 took 253.743s\n",
      "  training loss (in-iteration): \t4.899580\n",
      "  validation accuracy: \t\t\t7.32 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 6/15 [25:21<38:01, 253.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 6 of 15 took 253.503s\n",
      "  training loss (in-iteration): \t4.862000\n",
      "  validation accuracy: \t\t\t7.80 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 7/15 [29:34<33:48, 253.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 7 of 15 took 253.487s\n",
      "  training loss (in-iteration): \t4.825287\n",
      "  validation accuracy: \t\t\t8.36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 8/15 [33:47<29:33, 253.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 8 of 15 took 252.962s\n",
      "  training loss (in-iteration): \t4.795421\n",
      "  validation accuracy: \t\t\t8.50 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 9/15 [38:01<25:20, 253.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 9 of 15 took 253.487s\n",
      "  training loss (in-iteration): \t4.767249\n",
      "  validation accuracy: \t\t\t9.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 10/15 [42:14<21:06, 253.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 10 of 15 took 253.254s\n",
      "  training loss (in-iteration): \t4.740455\n",
      "  validation accuracy: \t\t\t9.29 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 11/15 [46:27<16:53, 253.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 11 of 15 took 253.455s\n",
      "  training loss (in-iteration): \t4.716852\n",
      "  validation accuracy: \t\t\t9.56 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 12/15 [50:40<12:39, 253.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 12 of 15 took 253.014s\n",
      "  training loss (in-iteration): \t4.694594\n",
      "  validation accuracy: \t\t\t9.74 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 13/15 [54:54<08:26, 253.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 13 of 15 took 253.299s\n",
      "  training loss (in-iteration): \t4.672462\n",
      "  validation accuracy: \t\t\t10.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 14/15 [59:07<04:13, 253.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 14 of 15 took 253.354s\n",
      "  training loss (in-iteration): \t4.651579\n",
      "  validation accuracy: \t\t\t10.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 15/15 [1:03:20<00:00, 253.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 15 of 15 took 253.442s\n",
      "  training loss (in-iteration): \t4.632497\n",
      "  validation accuracy: \t\t\t10.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit(model_vgg_4,train_batch_gen=train_batch_gen, val_batch_gen=val_batch_gen,optim=torch.optim.Adagrad,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Af0n9sPTxzkD",
    "outputId": "8997fe69-5c40-43fe-b9c6-d4cfbe8f41d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t10.49 %\n",
      "We need more magic! Follow instructons below\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4,test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "VlTSulu1xzkG",
    "outputId": "7c17b7c2-f5d1-4df1-d0da-cd60286fc94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  train accuracy:\t\t11.37 %\n",
      "We need more magic! Follow instructons below\n"
     ]
    }
   ],
   "source": [
    "predict(model_vgg_4, train_batch_gen,train_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvGMsV1VVsYh"
   },
   "source": [
    "# Report\n",
    "\n",
    "Below, please mention\n",
    "\n",
    "* a brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method (batch size, optimization algorithm, ...) and why?\n",
    "* Any regularization and other techniques applied and their effects;\n",
    "\n",
    "The reference format is:\n",
    "\n",
    "*\"I have analyzed these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrSK-qUgVsYi"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwhGU2_gxzkL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After models from seminar(where I took accuracy equal to 20%), I tried simple model with many layers < you wrote<br> \"This task can be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\">.<br> (I understand that low dimensions of image shape can beat me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='photo_2019-04-16_00-36-56.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And (after many hours) I achieved good val accuracy(more 40%) after 25 epochs but have a problem with low test accuracy approximately 7% (on val 40.99%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After googling (you can see attached links before model_vgg_3) I found a good article about [VGG-model](https://neurohive.io/en/popular-networks/vgg16/) and tried to implement it.<br>\n",
    "As you can see I made  VGG16(D)  models without the last (1 or 2) layers because I think that smaller shapes as in my first model will not achieved  a good result on test dataset.\n",
    "\n",
    "Firstly, I tried VGG like model without 2 last convolution layers and take learning rate = 1e-2. Unfortunately, I didn't get necessary accuracy and want to try MOAR layers. \n",
    "\n",
    "Also, I added everywhere BN because many papers (seminars) report that it increases speed of convergence and I added everywhere Dropout to prevent overfitting.\n",
    "\n",
    "If I added dropout after every linear-bn-relu layer it decreases accuracy of model and time of learning( I think that I excluded too much information) . And I decided to put one dropout after first dense layer.\n",
    "\n",
    "Secondly, I made model_vgg_4 and try it with learing rate = 1e-2.Then I didn't take accuracy on val and test more then 34. After many changes and my tears, I change learning rate to 1e-4 and got results above (best result val and test accuracy approximately 48). After 15 iteration the model started to approach to overfittind and I continued my reserch.  \n",
    "\n",
    "Thirdly, I build model_vgg_4 on not augmented data and got the same results. I think specially for last architecture  It doesn't influence on accuracy.\n",
    "\n",
    "Finally, I changed optimizer to Adagrad and got bad quality(accuracy) of this model.\n",
    "\n",
    "Also, you can see my child version of early stopping in fit function.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework_part2_vgg_final.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
