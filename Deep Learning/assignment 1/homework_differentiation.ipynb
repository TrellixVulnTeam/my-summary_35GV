{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it easy to google every task please please please try to undestand what's going on. The \"just answer\" thing will be not counted, make sure to present derivation of your solution. It is absolutely OK if you found an answer on web then just exercise in $\\LaTeX$ copying it into here. A good way to derive solutions for these tasks is to derive it for single elements and then generalize to the resulting matrix/vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links: \n",
    "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
    "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
    "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar w.r.t. vector:\n",
    "$$  \n",
    "y = c^Tx,  \\quad x \\in \\mathbb{R}^N \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = \n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\n",
    "\\frac{dy}{dx_i} = \\frac{d(c_1 x_1+c_2x_2+\\dots+c_N x_N)}{dx_i} = \\frac{d(c_i x_i)}{dx_i}= c_i\n",
    "$$ \n",
    "then as derivation has a vectro size: \n",
    "$$ \\frac{dy}{dx} = \\begin{pmatrix} \\frac{\\partial{y}}{x_1} \\\\ \\vdots \\\\ \\frac{\\partial{y}}{x_N} \\end{pmatrix}  =  \\begin{pmatrix} c_1 \\\\ \\vdots \\\\c_N \\end{pmatrix} = c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector w.r.t. vector:\n",
    "$$ y = \\sum_{j=1}^{N} cx^T \\quad c \\in \\mathbb{R}^{M} ,x \\in \\mathbb{R}^{N}, cx^T \\in \\mathbb{R}^{M \\times N} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} =\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\sum_{j=1}^{N} cx^T = \\begin{pmatrix}\n",
    "c_1 x_1 & \\dots & c_1 x_N \\\\\n",
    "\\vdots  & \\ddots & \\vdots \\\\\n",
    "c_M x_1 & \\dots & c_M x_N \n",
    "\\end{pmatrix}  = \\begin{pmatrix} c_1 \\sum_{i=1}^N x_i \\\\\n",
    "\\vdots \\\\ c_M \\sum_{i=1}^N x_i \\\\ \\end{pmatrix}\n",
    "\\to \\frac{dy}{dx} = \\begin{pmatrix} c_1 \\dots c_1 \\\\\n",
    "\\vdots \\\\ c_M \\dots c_M \\\\ \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Final matrix has shape (M,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector w.r.t. vector:\n",
    "$$  \n",
    "y = x x^T x , x \\in \\mathbb{R}^{N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} =\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ x x^T x = \n",
    "\\begin{pmatrix} x_1 \\\\ \\vdots \\\\x_N \\end{pmatrix} \\begin{pmatrix} x_1 & ... & x_N \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ \\vdots \\\\x_N \\end{pmatrix}  = \n",
    "\\begin{pmatrix}\n",
    "x_1^2 & x_1 x_2 \\dots & x_1 x_N \\\\\n",
    "\\vdots  & \\ddots & \\vdots \\\\\n",
    "x_N x_1 & x_N x_2 \\dots & x_N^2 \n",
    "\\end{pmatrix} \\begin{pmatrix} x_1 \\\\ \\vdots \\\\x_N \\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "x_1^3 & x_1 x_2^2 & \\dots & x_1 x_N^2 \\\\\n",
    "\\vdots & \\vdots  & \\vdots & \\vdots \\\\\n",
    "x_N x_1^2 & x_N x_2^2 &\\dots & x_N^3 \n",
    "\\end{pmatrix} \n",
    "$$\n",
    "And we can simplify it next way\n",
    "$$ xx^Tx =\n",
    "\\begin{pmatrix}\n",
    "x_1 \\sum_{i=1}^N x_i^2 \\\\\n",
    "\\vdots \\\\\n",
    "x_N \\sum_{i=1}^N x_i^2 \n",
    "\\end{pmatrix}\\text{ and finally we can find }  \\frac{dy}{dx} = \n",
    "\\begin{pmatrix}\n",
    "2x_1^2 + \\sum_{i=1}^N x_i^2 & \\dots & 2x_1 x_N \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "2x_N x_1 & \\dots & 2x_N^2 + \\sum_{i=1}^N x_i^2\n",
    "\\end{pmatrix} = \\boxed{x^T x I + 2xx^T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatives for the parameters of the Dense layer:\n",
    "\n",
    "***Given :***  $$Y = XW, Y \\in \\mathbb{R}^{N \\times OUT}, X \\in \\mathbb{R}^{N \\times IN}, W \\in \\mathbb{R}^{IN \\times OUT} $$ \n",
    "\n",
    "The derivative of the hypothetic loss function w.r.t. to $Y$ is known: $\\Delta Y  \\in \\mathbb{R}^{N \\times OUT}$\n",
    "\n",
    "***Task :*** Please, derive the gradients of the loss w.r.t the weight matrix $W$: $\\Delta W  \\in \\mathbb{R}^{IN \\times OUT}$. Use the chain rule. First, please, derive each element of the $\\Delta W$, then generalize to the matrix form.\n",
    " \n",
    "Useful link: http://cs231n.stanford.edu/vecDerivs.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's look at simple case:X & Y is row vectors) (2 chapter in book)\n",
    "$$\n",
    "y_i = \\sum_{j}^{} x_j W_{ji} \\to \\frac{\\partial{y_i}}{\\partial{W_{ji}}} = x_j\n",
    "$$\n",
    "and if we expand it on N dimension then we get:\n",
    "$$\n",
    "\\frac{\\partial{y_{ik}}}{\\partial{W_{jk}}} = x_{ij} \\to \\frac{dY}{dW} = X \\to \\Delta W = X^T \\Delta Y\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
